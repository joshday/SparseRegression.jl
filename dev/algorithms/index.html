<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Algorithms · SparseRegression.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">SparseRegression.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li><a class="tocitem" href="../usage/">Usage</a></li><li class="is-active"><a class="tocitem" href>Algorithms</a><ul class="internal"><li><a class="tocitem" href="#ProxGrad-1"><span>ProxGrad</span></a></li><li><a class="tocitem" href="#Fista-1"><span>Fista</span></a></li><li><a class="tocitem" href="#AdaptiveProxGrad-1"><span>AdaptiveProxGrad</span></a></li><li><a class="tocitem" href="#GradientDescent-1"><span>GradientDescent</span></a></li><li><a class="tocitem" href="#Sweep-1"><span>Sweep</span></a></li><li><a class="tocitem" href="#LinRegCholesky-1"><span>LinRegCholesky</span></a></li><li><a class="tocitem" href="#LineSearch-1"><span>LineSearch</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Algorithms</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Algorithms</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/joshday/SparseRegression.jl/blob/master/docs/src/algorithms.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Algorithms-1"><a class="docs-heading-anchor" href="#Algorithms-1">Algorithms</a><a class="docs-heading-anchor-permalink" href="#Algorithms-1" title="Permalink"></a></h1><p>The first argument of an <code>Algorithm</code>&#39;s constructor is an <code>SModel</code>.  This is to ensure storage buffers are the correct size.</p><h2 id="ProxGrad-1"><a class="docs-heading-anchor" href="#ProxGrad-1">ProxGrad</a><a class="docs-heading-anchor-permalink" href="#ProxGrad-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SparseRegression.ProxGrad" href="#SparseRegression.ProxGrad"><code>SparseRegression.ProxGrad</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ProxGrad(model, step = 1.0)</code></pre><p>Proximal gradient method with step size <code>step</code>.  Works for any loss and any penalty with a <code>prox</code> method.</p><p><strong>Example</strong></p><pre><code class="language-none">x, y, β = SparseRegression.fakedata(L2DistLoss(), 1000, 10)
s = SModel(x, y, L2DistLoss())
strat = strategy(MaxIter(50), ProxGrad(s))
learn!(s, strat)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/SparseRegression.jl/blob/dd43e36febba29332adf27b48eefa69a616891e5/src/algorithms/algorithms.jl#L90-L101">source</a></section></article><h2 id="Fista-1"><a class="docs-heading-anchor" href="#Fista-1">Fista</a><a class="docs-heading-anchor-permalink" href="#Fista-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SparseRegression.Fista" href="#SparseRegression.Fista"><code>SparseRegression.Fista</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Fista(model, step = 1.0)</code></pre><p>Accelerated proximal gradient method.  Works for any loss and any penalty with a <code>prox</code> method.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/SparseRegression.jl/blob/dd43e36febba29332adf27b48eefa69a616891e5/src/algorithms/algorithms.jl#L120-L124">source</a></section></article><h2 id="AdaptiveProxGrad-1"><a class="docs-heading-anchor" href="#AdaptiveProxGrad-1">AdaptiveProxGrad</a><a class="docs-heading-anchor-permalink" href="#AdaptiveProxGrad-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SparseRegression.AdaptiveProxGrad" href="#SparseRegression.AdaptiveProxGrad"><code>SparseRegression.AdaptiveProxGrad</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">AdaptiveProxGrad(s, divisor = 1.5, init = 1.0)</code></pre><p>Proximal gradient method with adaptive step sizes.  AdaptiveProxGrad uses element-wise  learning rates.  Every time the sign of a coefficient switches, the step size for that coefficient is divided by <code>divisor</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/SparseRegression.jl/blob/dd43e36febba29332adf27b48eefa69a616891e5/src/algorithms/algorithms.jl#L58-L64">source</a></section></article><h2 id="GradientDescent-1"><a class="docs-heading-anchor" href="#GradientDescent-1">GradientDescent</a><a class="docs-heading-anchor-permalink" href="#GradientDescent-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SparseRegression.GradientDescent" href="#SparseRegression.GradientDescent"><code>SparseRegression.GradientDescent</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">GradientDescent(model, step = 1.0)</code></pre><p>Gradient Descent.  Works for any loss and any penalty.</p><p><strong>Example</strong></p><pre><code class="language-none">x, y, β = SparseRegression.fakedata(L2DistLoss(), 1000, 10)
s = SModel(x, y, L2DistLoss())
strat = strategy(MaxIter(50), GradientDescent(s))
learn!(s, strat)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/SparseRegression.jl/blob/dd43e36febba29332adf27b48eefa69a616891e5/src/algorithms/algorithms.jl#L158-L169">source</a></section></article><h2 id="Sweep-1"><a class="docs-heading-anchor" href="#Sweep-1">Sweep</a><a class="docs-heading-anchor-permalink" href="#Sweep-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SparseRegression.Sweep" href="#SparseRegression.Sweep"><code>SparseRegression.Sweep</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Sweep(model)</code></pre><p>Linear/ridge regression via sweep operator.  Works for (scaled) L2DistLoss with NoPenalty or L2Penalty.  The <code>Sweep</code> algorithm has a closed form solution and is complete after one iteration.  It therefore doesn&#39;t need additional learning strategies such as <code>MaxIter</code>, <code>Converged</code>, etc.</p><p><strong>Example</strong></p><pre><code class="language-none">x, y, β = SparseRegression.fakedata(L2DistLoss(), 1000, 10)
s = SModel(x, y, L2DistLoss())
learn!(s, Sweep(s))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/SparseRegression.jl/blob/dd43e36febba29332adf27b48eefa69a616891e5/src/algorithms/algorithms.jl#L193-L206">source</a></section></article><h2 id="LinRegCholesky-1"><a class="docs-heading-anchor" href="#LinRegCholesky-1">LinRegCholesky</a><a class="docs-heading-anchor-permalink" href="#LinRegCholesky-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SparseRegression.LinRegCholesky" href="#SparseRegression.LinRegCholesky"><code>SparseRegression.LinRegCholesky</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LinRegCholesky(model)</code></pre><p>Linear/ridge regression via cholesky decomposition.  Works for (scaled) L2DistLoss with NoPenalty or L2Penalty.  The <code>LinRegCholesky</code> algorithm has a closed form solution  and is complete after one iteration.  It therefore doesn&#39;t need additional learning strategies such as <code>MaxIter</code>, <code>Converged</code>, etc.</p><p><strong>Example</strong></p><pre><code class="language-none">x, y, β = SparseRegression.fakedata(L2DistLoss(), 1000, 10)
s = SModel(x, y, L2DistLoss())
learn!(s, Sweep(s))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/SparseRegression.jl/blob/dd43e36febba29332adf27b48eefa69a616891e5/src/algorithms/algorithms.jl#L248-L261">source</a></section></article><h2 id="LineSearch-1"><a class="docs-heading-anchor" href="#LineSearch-1">LineSearch</a><a class="docs-heading-anchor-permalink" href="#LineSearch-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="SparseRegression.LineSearch" href="#SparseRegression.LineSearch"><code>SparseRegression.LineSearch</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">LineSearch(algorithm)</code></pre><p>Use a line search in the <code>update!</code> of <code>algorithm</code>.  Currently, <a href="#SparseRegression.ProxGrad"><code>ProxGrad</code></a>, <a href="#SparseRegression.Fista"><code>Fista</code></a>, and <a href="#SparseRegression.GradientDescent"><code>GradientDescent</code></a> are supported.</p><p><strong>Example</strong></p><pre><code class="language-none">x, y, β = SparseRegression.fakedata(L2DistLoss(), 1000, 10)
s = SModel(x, y, L2DistLoss())
strat = strategy(MaxIter(50), LineSearch(ProxGrad(s)))
learn!(s, strat)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/joshday/SparseRegression.jl/blob/dd43e36febba29332adf27b48eefa69a616891e5/src/algorithms/algorithms.jl#L21-L33">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../usage/">« Usage</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 3 January 2020 08:01">Friday 3 January 2020</span>. Using Julia version 1.1.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
